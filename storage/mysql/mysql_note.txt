
 DDL（Data Definition Language）数据库定义语言: DDL不需要commit. CREATE ALTER DROP TRUNCATE COMMENT RENAME
 DML（Data Manipulation Language）数据操纵语言: 需要commit. SELECT INSERT UPDATE DELETE MERGE CALL EXPLAIN PLAN LOCK TABLE
 DCL（Data Control Language）数据库控制语言  授权，角色控制等: GRANT 授权 REVOKE 取消授权
 TCL（Transaction Control Language）事务控制语言: SAVEPOINT 设置保存点 ROLLBACK 回滚  SET TRANSACTION
（1）数据定义。（SQL DDL）用于定义SQL模式、基本表、视图和索引的创建和撤消操作。
（2）数据操纵。（SQL DML）数据操纵分成数据查询和数据更新两类。数据更新又分成插入、删除、和修改三种操作。
（3）数据控制。包括对基本表和视图的授权，完整性规则的描述，事务控制等内容。
（4）嵌入式SQL的使用规定。涉及到SQL语句嵌入在宿主语言程序中使用的规则。


 查看性能：https://www.cnblogs.com/fyy-hhzzj/p/9044166.html
 mysqladmin status -uroot -p'admin' -P3306  -h127.0.0.1
 mysqladmin -h127.0.0.1 -uroot -p'admin'  extended-status [--relative --sleep=1]
  tps: Transactions Per Second，每秒事务数；   TPS=Com_commit/s + Com_rollback/s = Com_insert/s + Com_update/s + Com_delete/s  
  qps: Queries Per Second每秒查询数；          QPS = mysqladmin extended-status --relative --sleep=1|grep -w Questions = Com_select/s + Com_insert/s + Com_update/s + Com_delete/s
  Com_select/s = mysqladmin extended-status --relative --sleep=1|grep -w Com_select
  Com_select/s：平均每秒select语句执行次数
  Com_insert/s：平均每秒insert语句执行次数
  Com_update/s：平均每秒update语句执行次数
  Com_delete/s：平均每秒delete语句执行次数
 
 
 线上主从：
 数据库授权：在旧主库上授权	
 grant replication slave on *.* to myrync@'103.248.20.34' identified by 'MyryncCloud';
 并刷新权限flush privileges;	   
 做 主（旧主库）从（新主库） 从（新从库）
 主从从思路：
 1.主从的时候，mysqldump---备份一下mysql库(有授权信息)
 mysqldump -uroot -p -S /opt/data/data_16303/mysql.sock -P16303 -B mysql > /home/swadmin/mysql.sql
 2.每天有全备的，拷贝即可
   /backup/data_back/full
   innobackupex  --defaults-file=/opt/conf/my_16303.cnf  --use-memory=10G --compress --compress-threads=24  -uroot -p9tN6GFGK60Jk8BNkBJM611GwA66uDFeG  -S  /opt/data/data_16303/mysql.sock  /opt/src/upload/full
 3.同时拷贝旧站到新的主库和从库，
 4.恢复数据，(less /opt/src/upload/full/2018-05-20_12-33-46/xtrabackup_binlog_info)
   停止新主备站mysql服务并清空新主备站的数据目录
   解压：innobackupex --decompress --parallel=16 /opt/src/upload/full/2018-05-20_12-33-46/
   应用：innobackupex --apply-log --use-memory=4G  /opt/src/upload/full/2018-05-20_12-33-46/ 
   恢复：innobackupex --defaults-file=/opt/conf/my_slave_16303.cnf --use-memory=4G  --move(copy)-back  /opt/src/upload/full/2018-05-20_12-33-46/
   注意：改权限swadmin
   启动： mysqld --defaults-file=/opt/conf/my_16303.cnf  --user=swadmin &
 5.source  备份的mysql库 ，再flush privileges;
 6.新主从库先做主从 (在主库上show master status； 记住与上面步骤4的区别)
   CHANGE MASTER TO
   MASTER_HOST='154.223.1.77',
   MASTER_USER='myrync',
   MASTER_PASSWORD='MyryncCloud',
   MASTER_PORT=16303,
   MASTER_LOG_FILE='mysql-bin.000333',
   MASTER_LOG_POS=379096239;
 7.再在线上主库和新主库上做主从(偏移量参考步骤4)
 
 
 
 show variables like "%logs_days%";               查看变量
 set global expire_logs_days=7;                   设置变量
 flush logs;   &&  purge binary logs to 'bin.5';  &&   purge binary logs before '2017-05-01 13:09:51';    刷新binlogs日志&&删除bin.5之前日志&&删除指定时间之前日志 
 
 select * from information_schema.innodb_trx;    (INNODB_TRX表主要是包含了正在InnoDB引擎中执行的所有事务的信息，包括waiting for a lock和running的事务)
 
 select * from information_schema.innodb_lock_waits;  (INNODB_LOCKS表主要包含了InnoDB事务锁的具体情况，包括事务正在申请加的锁和事务加上的锁。)
 
 select * from information_schema.innodb_lock_waits;  (INNODB_LOCK_WAITS表包含了blocked的事务的锁等待的状态)
 
 
 show processlist；/ select * from information_schema.processlist  显示用户正在运行的线程,除了 root 用户能看到所有正在运行的线程外，其他用户都只能看到自己正在运行的线程，看不到其它用户正在运行的线程。除非单独个这个用户赋予了PROCESS 权限。
 按客户端 IP 分组，看哪个客户端的链接数最多
 select client_ip,count(client_ip) as client_num from (select substring_index(host,':' ,1) as client_ip from information_schema.processlist ) as connect_info group by client_ip order by client_num desc;
 +-------------+------------+
 | client_ip   | client_num |
 +-------------+------------+
 | 154.92.6.15 |        377 |
 | 154.92.5.13 |        101 |
 | localhost   |          1 |
 +-------------+------------+
 查看正在执行的线程，并按 Time 倒排序，看看有没有执行时间特别长的线程
 #select client_ip,count(client_ip) as client_num from (select substring_index(host,':' ,1) as client_ip from information_schema.processlist ) as connect_info;
 #+-------------+------------+
 #| client_ip   | client_num |
 #+-------------+------------+
 #| 154.92.6.15 |        479 |
 #+-------------+------------+
 select * from information_schema.processlist where Command != 'Sleep' order by Time desc;
 找出所有执行时间超过 5 分钟的线程，拼凑出 kill 语句，方便后面查杀select concat('kill ', id, ';') from information_schema.processlist where Command != 'Sleep' and Time > 300 order by Time desc;
 
 set global read_only=0; ----> show variables like '%read_only'; ---> read_only OFF 
 
 查看从库状态：
 show slave status\G;
 
 测试授权用户连接：mysql  -u用户名  -h授权ip    -P端口 -p
 本地登陆：mysql  -uroot -p -S /opt/data/data_16303/mysql.sock [-P16303 -h127.0.0.1]
 导出全部数据库:mysqldump -uroot -p --all-databases > sqlfile.sql
 导出库：mysqldump -uroot -p -S /opt/data/data_16303/mysql.sock -P16303 -B gameplat_cms > /opt/src/upload/cms.sql
       [--single-transaction --master-data=2 -opt]
 导入库：mysql -uroot -p -S /opt/data/data_16303/mysql.sock gameplat_cms < cms.sql
 导出表：
 mysqldump -u 用户名 -p -S /opt/data/data_16303/mysql.sock 数据库名 表名 > 导出的文件名	
 mysqldump -uxxx -pxxx -hxx.xx.xx.xx -P 16303 -B luckydb --tables t1 t2 >./1.log
 mysql -uroot -D数据库名 -S /opt/data/data_16303/mysql.sock 表名
 部分数据导出：mysqldump -h IP -u用户名 -p密码 数据库名 表名 --where="筛选条件">导出文件路径;
 恢复：进到相应库source
 

##################################################################################### 
 
   授权：grant 权限列表 on 库名.表名 to "用户名"@"%(ip)" identified by "密码"  with grant option;   #授权同时如果没有用户会自动创建
			 create user '用户'@'ip' identified by '密码';   #创建一个只登陆用户
			 grant  权限 on "库名"."表名" to   "用户名"@"ip";
   列级授权：grant select(id,name),update(add_time) on '用户'@'ip' to "用户名"@"%(ip)" identified by '密码';
   删除权限: revoke 权限 on "库名"."表名" from "用户名"@"ip";
   查看授权：show grants for user@host;           #查看用户授权
             select user,host from mysql.user;    #查看用户，包括管理员
	         select user,host,db from mysql.db;   #查看具体数据库授权，不记录所有库的授权	
			 select * from mysql.tables_priv;     #查看具体到表的授权。
			 select * from mysql.columns_priv;    #查看列级授权
	删除用户：drop user  "用户名"@"ip";           #删除了权限用户还在，删除用户权限也会一起删除

##################################################################################### 

 
 从库取消主从：stop slave；reset slave all;
 
 主从授权：grant replication slave on *.* to myrync@'$i' identified by 'MyryncCloud';
           flush privileges;
		   
 查看信息：show master status;
 
 MySQL中source命令   mysql> source *.sql;     //导入数据 
 
 
 Innobackupex：https://www.percona.com/downloads/[Percona-XtraBackup-LATEST/]
 增量备份的基础是InnoDB引擎使用了LSN机制，非InnoDB引擎不存在增量备份的说法，每次都是全备（差量备份是针对全备的，增量备份可以基于全量/差量/增量基础上）。
 全备文件：2018-05-20_12-33-46
 差异文件：/backup/data_back/incre/2018-05-20_12-33-46/*
 全备：innobackupex  --defaults-file=/opt/conf/my_16303.cnf  --use-memory=10G --compress --compress-threads=24  -uroot -p9tN6GFGK60Jk8BNkBJM611GwA66uDFeG  -S  /opt/data/data_16303/mysql.sock  /opt/src/upload/full
 差异备：innobackupex  --defaults-file=/opt/conf/my_16303.cnf  --use-memory=10G --compress --compress-threads=24  -uroot -p  -S  /opt/data/data_16303/mysql.sock  --incremental /backup/data_back/xtrabackup/incre/2018-05-20_12-33-46 --incremental-basedir /backup/data_back/xtrabackup/full/2018-05-20_12-33-46
 停止mysqld服务，清空data_16303/目录
 解压全备：innobackupex --decompress --parallel=16 /backup/data_back/full/2018-05-20_12-33-46/
 应用日志等待回滚：innobackupex --apply-log --use-memory=4G --redo-only /backup/data_back/full/2018-05-20_12-33-46/
 #解压差异备份：innobackupex --decompress --parallel=16 /backup/data_back/incre/2018-05-20_12-33-46/2018-05-20_13-00-09/
 #合并日志回滚：innobackupex --apply-log --use-memory=4G /backup/data_back/full/2018-05-20_12-33-46/  --incremental-dir=/backup/data_back/incre/2018-05-20_12-33-46/2018-05-20_13-00-09/
 可查看这个文件：less /backup/data_back/full/2018-05-20_12-33-46/xtrabackup_checkpoints---lsn是否最新(有变化)
 恢复数据：innobackupex --defaults-file=/opt/conf/my_16303.cnf --use-memory=4G  --copy(move)-back  /backup/data_back/full/2018-05-20_12-33-46/
 启动服务：mysqld --defaults-file=/opt/conf/my_16303.cnf  --user=swadmin &  （数据目录权限值得看一下）
 增量备份：
	innobackupex --user=root --password=123456 --no-timestamp --incremental-basedir=/backup/mysql/full --incremental /backup/mysql/01
	innobackupex --user=root --password=123456 --no-timestamp --incremental-basedir=/backup/mysql/01 --incremental /backup/mysql/02
 
 时点恢复:结合binlog将Mysql数据库恢复到指定时间点
 
 显示数据表结构:  desc 表名;   //   describe 表名;
 
 远程登陆mysql：mysql -hlocalhost -uroot -p -P3306 -S /opt/data/data_16303/mysql.sock
 使用gzip命令对备份文件进行压缩：：mysqldump phpbb_db_backup | gzip > /usr/backups
 
 
 mysql授权表共有5个表：user、db、host、tables_priv和columns_priv。
 user表列出可以连接服务器的用户及其口令，并且它指定他们有哪种全局（超级用户）权限。在user表启用的任何权限均是全局权限，并适用于所有数据库。例如，如果你启用了DELETE权限，在这里列出的用户可以从任何表中删除记录，所以在你这样做之前要认真考虑。
 db表列出数据库，而用户有权限访问它们。在这里指定的权限适用于一个数据库中的所有表。
 host表与db表结合使用在一个较好层次上控制特定主机对数据库的访问权限，这可能比单独使用db好些。这个表不受GRANT和REVOKE语句的影响，所以，你可能发觉你根本不是用它。
 tables_priv表指定表级权限，在这里指定的一个权限适用于一个表的所有列。
 columns_priv表指定列级权限。这里指定的权限适用于一个表的特定列。
 
##################################################################################### 
 
 mysql> help          帮助命令
 mysql> help contents;  --->  help Account Management  --->  help CREATE USER  [查看库时命令 show create database ilanni;]  [关于主从：help transactions;]
 mysql> system  cmd   
 命令行执行命令：mysqld_safe/mysql –defaults-file=  -u用户 -p -S 本地sock文件 -e "sql命令"
 初始化：mysql_install_db  –help(–basedir=bin路径  –datadir=数据目录 –user=mysql )
 密码：mysqladmin -uroot [旧密码-p123456} password 456789  / [help set password; 修改密码]
 查看授权：mysql> use information_schema; --->  desc user_privileges; --->  select privilege_type from user_privileges; / show privileges;
 
 
##################################################################################### 
 
 索引：
 alter table table_name add index index_name (column_list)/unique (column_list)/primary key (column_list) ;
 create [unique] index index_name on table_name (column_list) ;
 删除索引:
 drop index index_name on table_name ;
 alter table table_name drop index index_name/primary key ;
 #hash只适合找固定值  二叉树存在平衡问题  红黑AVL树(平衡二叉树的一种,还是容易倾斜) 使用的是B+tree
 
 for i in $ip;do
 expect << EOF
         spawn /opt/apps/mysql/bin/mysql -uroot -p -S /opt/data/data_16303/mysql.sock -e "    
         grant all privileges on gameplat_analysis.* TO 'gameplat_analysis_dev'@'$i' identified by 'xjVXkB>Q6JpB61r${rand_pass}';
         flush privileges;"
         expect "Enter password:" {send "9tN6GFGK60Jk8BNkBJM611GwA66uDFeG\r"}
         expect eof
 EOF
 done
 
配置文件：
	[mysqld]
	charactr_set_server = utf8      #默认字符集 
库操作： 
    查库：show databases;   (库名区分大小写)
    位置：select database;
    建库：create database [if not exists] 库名 character set utf8;
    查看：show create database 库名;
    删库：drop database 库名; 
    进入指定库：use 库名;
表操作：
    查表：show tables;
    查表:show create table 表名;
    建表：create table 表名(字段名 数据类型, ...)character set utf8 engine=MyISAM;
    删表：drop table 表名;
	清空表中记录：delete from 表名;  //  truncate table "表名";

    表结构：desc 表名;
  对行的操作：
  	INSERT INTO 表名称 (列1, 列2,...) [VALUES (值1, 值2,....)]
      insert into mytable values('summer','m','1983-08-24');   
    删除一条记录：delete from mytable where name='summer';  
    UPDATE 表名称 SET 列名称 = 新值 WHERE 列名称 = 某值	
      update mytable set sex='vm' where name='summer';   
    插入多条记录：insert into mytable  select * from yourtable;  
    根据条件插入：insert into mytable  select * from yourtable where `key`='value';
  对列的操作：
    alter table 表名 add 列名 列数据类型 [after 插入位置];
      alter table yourtable add  name varchar(20)not null; 
    alter table 表名 change 列名称 列新名称 新数据类型;	  
	alter table 表名 drop 列名称;
	alter table 表名 rename 新表名;
  索引：
    普通index：
	ALTER TABLE 表名 ADD INDEX 索引名字 ( 字段名字 )  #修改表结构方式添加
	  CREATE INDEX index_user ON user(title)		  #直接添加/创建表的时候添加
	DROP INDEX index_name ON table					  #删除索引
	主键PRIMARY key：
	ALTER TABLE 表名字 ADD PRIMARY KEY ( 字段名字 )
	唯一索引(UNIQUE)
	ALTER TABLE 表名字 ADD UNIQUE (字段名字)
	全文索引(FULLTEXT)
	ALTER TABLE 表名字 ADD FULLTEXT (字段名字)
	多列索引：多个字段做一个索引
	ALTER TABLE table_name ADD INDEX index_name ( column1, column2, column3)
	
！！
  建表：create table 表名(字段名 数据类型, ...)character set utf8 engine=MyISAM;	  
  查看: 
    SELECT 列名称 FROM 表名称 WHERE 列 运算符 值   
		列名称：列, 列..[as '姓名'] // 集合函数 count(*) avg(列) max(列) min(列) sum(列)
		表名称：表名 // 子查询
		where： and/or // =,<>,<,<=,>,>= // not //[not] in // between and // like '[^AC]%'
			like：模糊查询 #_:匹配单个字符   %:匹配0到多个字符
			in：查询结果在in里面  #select * from A where id in (select id from B) 当B表的数据集必须小于A表的数据集时
			#exists: 当A数据集小于B，语法也比较复杂
		as: 別名  #select column_1 as 列1,column_2 as 列2 from table as 表
		distinct:不显示字段的重复值。语法：select distinct 字段1, 字段2 from 表名；distinct和from之间的所有字段值都相同才会去重
		group by：显示(sum)效果列
		having：WHERE 关键字无法与合计函数一起使用   HAVING SUM(OrderPrice)<2000
		order by：语句用于根据指定的列对结果集进行排序。DESC降序ASC顺序				
	  两个表：
		联合查询union - 用于合并两个或多个 SELECT 语句的结果集。  #UNION ALL命令和UNION命令几乎是等效的，不过UNION ALL命令会列出所有的值(包括重复的)。
		连接查询join on: inner join(相同的) // left join(左边全显示,右边不存在显示null，右边多余存在忽略) // right join(右边全显示,左边不存在显示null，左边多余存在忽略) // full outer join(并集,全都显示) #join与on配合(on和where一样)，更细致的用法是后面带where条件(key is null)
        #select [查询列表 as 别名⑤] from [表1 as 别名 连接类型 join 表2 as 别名 on 连接条件①] [where 筛选条件②] [group by 分组③] [having 筛选条件④]  [order by 排序列表⑥]
  对行的操作：
  	插入表记录：  insert into 表名(列1, 列2,...) [VALUES (值1, 值2,....)]  #insert into mytable values('summer','m','1983-08-24');   #插入多条记录：insert into 表名  select * from yourtable;
    删除一条记录：delete from 表名 where name='summer';  
    更新表记录：  update 表名 set 列名 = 新值 where 列名 = 某值	 		   #update mytable set sex='vm' where name='summer';     
  对列的操作：
	修改表名：alter table 表名 rename 新表名;
    修改列名：alter table 表名 change 列名称 列新名称 新数据类型;	  	
	删除列：  alter table 表名 drop 列名称;	
	添加列：  alter table 表名 add 列名 列数据类型 [after 插入位置];  #alter table yourtable add  name varchar(20)not null; 
  索引：
   查看：show index from 表名;   （普通和主键和全文索引有容易看出来的名称，没有的就是唯一索引）
   创建：
	多列索引：  alter table 表名  add index 索引名(列名1,列名2,...);      #只有一列叫普通索引，多列叫多列索引
	唯一索引：  alter table 表名  add unique      (列名1,列名2,...);	  #唯一但允许空值，外键要唯一或主键索引
	主键索引：  alter table 表名  add primary key (列名1,列名2,...);	  #唯一且不允许空值，不允许建立多个(可与其他索引共存)
	全文索引：  alter table 表名  add fulltext    (列名1,列名2,...); 	  #支持myisam，不支持innodb
    外键：      alter table 表名1 add foreign key (列名) references 表名2(列名); #一张表可以有多个外键字段（与主键不同）
   删除索引：
	  主键：    alter table 表名 drop primary key;
	  主键之外：alter table 表名 drop index 索引名;
   查看授权：show grants for user@host;           #查看用户授权
   授权：    grant  权限 on "库名"."表名" to   "用户名"@"ip" identified by "密码"  with grant option;   #授权同时如果没有用户会自动创建
   删除权限: revoke 权限 on "库名"."表名" from "用户名"@"ip";
   删除用户：drop user  "用户名"@"ip";         #删除了权限用户还在，删除用户权限也会一起删除
   视图：create view 视图名 as 结果集;
	     alter  view 视图名 as 结果集;
 
 数据类型：1.节省空间(varchar)    2.效率高(char)
	数值类型宽度(显示宽度，不够用0补充)和存储没有关系[有/无符号signed/unsigned],decimal(m,n)整数部分和小数部分分开存储
	字符类型宽度不够则无法存入
	枚举 单选enum  多选set
	时间 datetime(Null) = timestamp(系统时间) = date("年月日") + time("时分秒")
 
 日期时间函数：
 now()				返回服务器当前时间
 curldate()			当前日期
 date("datetime")	提取年月日
 time("datetime") 	提取时分秒
 year("datetime")	提取年
 
 日期时间运算：where * from 表名 where 字段名 运算符(now()-interval 时间间隔单位(1 day));
 
 表字段操作:alter table 表名 操作(add/drop/modify/rename/change) 字段名 数据类型 位置(first/after 字段名)；
 表记录操作：
	删除：delete from 表名 where 条件;
	更新：update 表名 set 字段1=值1, ...where 条件(可以使用括号()); 
 
 NULL：空值，只能用is、is not 去匹配
 "":空字符串，只能用 =  != 去匹配
 模糊查询(like)
	where 字段名 like 表达式
	_:匹配单个字符   %:匹配0到多个字符
	
  集合函数：
	avg(字段名)：平均值
	sum   max  min   count
	
 高级查询：表达式从行而下顺序结构
	select ...聚合函数 from 表名
	where  ...
	group by ...:给查询的结果进行分组
	having  ...：对查询结果进一步筛选
	order by  字段名 ASC/DESC : 给查询结果排序 
	limit [m,]n  ：显示查询记录的第m条开始，条数n

 distinct:不显示字段的重复值。语法：select distinct 字段1, 字段2 from 表名；
	distinct和from之间的所有字段值都相同才会去重
 
 约束constraint：保证数据的一致性，有效性
	分类：1.默认约束(default)    2.非空约束(not null)
 
 索引：对数据库中表的一列或多列的值进行排序的一种结构(BTree)
	优点：加快数据的检索速度
	缺点：1.数据更新时，索引需要动态维护，降低数据的维护速度    2.索引需要占用物理存储空间
 1.索引运行时间检测： set profiling=1；(show variables like "profiling")
 2.执行查询语句：
 3.查看执行时间：show profiles;
 4.选择一个字段创建索引:create index name on t1(name);
 5.再次执行查询语句并查看执行时间，进行比较
 
 1.普通索引(index):1.可设置多个字段,字段值无约束   2.把经常用来查询的字段设置为索引字段   3.key标志：MUL
		创建表时：create table t1(...,...,),index(name),index(id),...);
		已有表中：create index 索引名  on  表名(字段名)；
		查看：1.desc 表名;    2.show  index from 表名\G; 
		删除：drop index 索引名 on 表名;
 2.唯一索引(unique)&&自增长(auto_increment):1.可设置多个字段   2.字段值不允许重复，但可以为空值   3.key标志：UNI
		创建表时：create table t1(...,...,),unique(name),unique(id),...);
		已有表中：create unique index 索引名  on  表名(字段名)；
		查看：1.desc 表名;    2.show  index from 表名\G; 
		删除：drop index 索引名 on 表名;
 3.主键索引(primary key):1.只能有一个字段为主键字段   2.字段值不允许重复，也不能为NULL  
						 3.KEY标志：PRI    4.通常设置记录编号字段id，能够唯一锁定一条记录（自增长修改初始值：alter table 表名 AUTO_INCREMENT=10000;）
		创建表时：... id int primary key auto_increment      复合主键(两个id与name同时相同才会报错)：id int auto_increment,name varchar(20),primary key(id,name)
		已有表中:alter table 表名 add primary key(id);
		删除：1.删除自增长属性modify:alter table 表名 modify id int  2.alter table 表名 drop primary key;
 4.外键(foreign key):让当前的字段值在另一张表的范围内去选择，主从表字段数据类型要一致，主表：被参考字段是主键
		创建表时：...foreign key(参考字段名) reference 主表(被参考字段名) on delete 级联动作(cascade) on update 级联动作
		已有表时：alter table 表名 add foreign key(参考字段名) reference 主表(被参考字段名) on delete 级联动作 on update 级联动作
		删除外键：alter table 表名 drop foreign key 外键名;
		查看外键: show create table 表名;
		级联动作：1.cascade：数据级联删除，级联更新   2.restrict(默认)：从表中有相关联记录，不允许主表操作   3.set null：主表删除，更新，从表相关联记录字段值为NULL
 
 数据导入：把文件系统中内容导入到数据库中(.csv 可用execl表格打开)
	语法格式：load  data infile "文件名"  into table 表名 fields terminated by "分隔符" lines terminated by "\n";
	导入：1.在数据库中创建对应的表   2.1查看搜索路径show variables like "secure_file_priv"     2.2 执行数据导入,文件需在指定目录下
 数据导出：把输出到终端的数据表的记录导出到系统文件里
	语法格式： select ... from 表名 into outfile "文件名" fields terminated by "分隔符" lines terminated by "\n";
 
 表的复制：
	语法：create table 表名 select ... from 表名 where 条件;
 
 复制表结构：
	语法：create table 表名 select ... from 表名 where false;
 
 嵌套查询(子查询)：把内层的查询结果作为外层的查询条件
	语法：select ... from 表名 where 字段名 运算符 (select ... from 表名 where 条件);
 
 多表查询：
	1.笛卡尔积：不加where条件
		语法：select ... from 表1,表2;  
	2.加where条件
		语法: select ... from 表1,表2 where 条件;
 
 连接查询：多张表(比多表查询效率高)
	1.内连接(inner join)
		语法格式: select 字段名列表 from 表1 inner join 表2 on 条件 inner join 表2 on 条件 ...;
	2.外连接：没匹配到的用NULL填充
		2.1 左连接(left join):以左表为主，显示查询结果
			select 字段名列表 from 表1 left join 表2 on 条件 left join 表2 on 条件;			
		2.2 右连接(right join)：以右表为主显示查询结果
			select 字段名列表 from 表1 a right outer join 表2 on 条件;
			
 锁：解决客户端并发访问的冲突问题
	分类：
		锁类型：读锁(共享锁)：有读锁时，无法更改      写锁(互斥锁，排他锁)：有写锁时，无法查与更新
		锁粒度：行级锁row：Innodb          表级锁：MyISAM
 
 存储引擎(engine：处理表的处理器):
	查看所有：show engines;
	查看已有表：show create table 表名;
	指定：create table ... engine=myisam charset=utf8;  或 alter table 表名 engine=myisam;
  InnoDB: 聚集索引方式(叶子节点就是对应的数据节点)
		1.支持事务、外键、行级锁    
		2.共享表空间
		3.写性能好
			表名.frm:表结构和索引信息
			表名.idb:表记录
  Myisam：非聚集索引方式(叶节点仍然是索引节点，只是有一个指针指向对应的数据块)
		1.支持表级锁
		2.独享表空间
		3.读性能好
			表名.frm:表结构
			表名.MYD:表记录
			表名.MYI:索引信息
  Memory：数据存于内存中，重启表数据消失，表结构还在硬盘
  
  聚集索引方式: 逻辑顺序与磁盘上行的物理存储顺序相同，叶子节点就是对应的数据节点
  非聚集索引方式: 叶节点仍然是索引节点，只是有一个指针指向对应的数据块--B+tree
  #聚集索引直接获取到对应的全部列的数据，而非聚集索引在索引没有覆盖到对应的列的时候需要进行二次查询
  #主键是创建聚集索引的表在数据插入上比主键上创建非聚集索引表速度要慢
  
	执行查询操作多的表使用Myisam     执行写操作多的表使用innodb
 
	账号管理：授权连接
		grant 权限列表 on 库名.表名 to "用户名"@"%(ip)" identified by "密码"  with grant option;
		权限列表：all privileges、select 库表.表名、update 库表.表名
 
	数据备份：命令行
		完整备份：mysqldump -u用户名 -p 源库名 > **.sql
			源库名：--all-databases         #所有库
					库名      				#单个库
					-B 库名1 库名2 ...      #多个库
					库名 表1 表2 ...		#多表
		恢复：mysql -u用户名 -p 目标库名 < **.sql		(恢复指定库需要先从库)
			mysql -u用户名 -p --one-database 库名 < **.sql (从全部备份中恢复一个库，先创建库)
			恢复库时，要先创建，如果已有库恢复，同名表数据会被覆盖，新增表不会被删除
		增量备份：

 查看执行过的sql语句：1. show binlog events in 'mysql-bin.000021'\G;
 					  2. mysqlbinlog mysql-bin.000001 | grep -E "^SET T" -C 1
					  #show  master logs;  查看binlog日志文件名
					  #show  master status; 查看当前写入的binlog文件
 @x 是 用户自定义的变量
 @@x 是 global或session变量


	调优：1.创建索引：(select where order by常涉及到的字段)
		2.选择合适存储引擎：执行查询操作多的表使用Myisam     执行写操作多的表使用innodb
		3.sql语句优化(避免全表扫描)
			1.where 子句尽量不适用 !=  ，否则全表扫描
			2.尽量避免NULL判断is null，否则全表扫描
				解决方法：字段设置not null/默认值0
			3.尽量避免用or连接条件，否则全表扫描
				解决方法：sql语句用union all拼接
			4.模糊查询尽量避免使用前置%  ,否则全表扫描
			5.尽量避免使用in和not in,否则全表扫描	
				优化前：select id from t1 where id in(1,2,3);
				优化后: select id from t1 where id between 1 and 4;
			6.不要使用select * ...
				解决方法：用具体字段代替* , 不返回用不到的字段
	事务和事务回滚：
		事务：一件事从开始发生到结束的整个过程，确保数据的一致性
		应用：1.begin;(自动关闭autocommit)    2. sql命令...      3.commit;(提交)/rollback;(回滚)

	图形化管理工具：workbench




 mysql逻辑架构：1.连接层  2.服务层  3.引擎层  4.存储层
	
 机读： from // on + join // where // group by // having // select // distinct // order by
 sql join: inner  left  right  
 
 	join连接：  1.左连接建右表索引，右连接建左表索引。2.尽可能减少join语句中的nestedloop的循环总次数："永远用小结果集驱动大的结果集" (个人觉得是explain中的rows) 
				3.保证join语句中被驱动表上join条件字段已经被索引   2.内存资源充足的前提下，使用joinbuffer的设置
	
 
 数据只进行逻辑删除：1.数据分析  2.方便索引
		
	
	
	
触发器：脚本https://www.cnblogs.com/javabg/p/9990078.html
	创建的触发器是在某个表上的
DELIMITER $			#设置结束符
CREATE TRIGGER user_log AFTER INSERT ON logs FOR EACH ROW
#创建触发器名称为user_log在插入logs表每一行AFTER之后执行
BEGIN
DECLARE s1 VARCHAR(40)character set utf8;
DECLARE s2 VARCHAR(20) character set utf8;
SET s2 = " is created";
SET s1 = CONCAT(NEW.log,s2);
INSERT INTO logs(log) values(s1);
END $
DELIMITER ;
	
	DELIMITER $$
	CREATE PROCEDURE `partition_maintenance_all`(SCHEMA_NAME VARCHAR(32))
	BEGIN
					CALL partition_maintenance(SCHEMA_NAME, 'history', 7, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'history_log', 7, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'history_str', 7, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'history_text', 7, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'history_uint', 7, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'trends', 365, 24, 14);
					CALL partition_maintenance(SCHEMA_NAME, 'trends_uint', 365, 24, 14);
	END$$
	DELIMITER ;
	#CREATE PROCEDURE 语句：在数据库中创建用户定义的 SQL 过程。
	#以上代码部分的含义为(库名,表名,保存多少天的数据,每隔多久生成一个分区,本次生成多少分区）
		
	truncate table history;   ##删除整张表数据，但不会缩小表结构 
	optimize table tablename; ##删除数据后的优化 
	
	
mysqld --verbose --help  #使用命令查看帮助
	#脚本启动
		## 设置变量
		MYSQL_PATH="/usr/local/mysql"
		sql_conf_dir='/usr/local/mysql/conf'
		sql_conf_file=$(ls $sql_conf_dir/* |egrep cnf$)
		sql_user='mysql'
		
		su ${sql_user} -s /bin/bash -c "${MYSQL_PATH}/bin/mysqld --defaults-file=${sql_conf_file} --user=${sql_user} &"  #启动
		#su ${sql_user} -s /bin/bash -c "source /etc/profile && mysqld --defaults-file=${sql_conf_file} --user=${sql_user} &"
		/opt/apps/mysql/bin/mysqladmin -uroot -p -S /opt/data/data_16303/mysql.sock -P 16303 shutdown					 #关闭	
	
安装：安装的时候保证没有其它mysql/mariadb程序的存在或残留文件存在，不然容易命令错误(which mysql ...)
	mysqld是mysql的核心程序  mysqld_safe脚本会在启动MySQL服务器后继续监控其运行情况，并在其死机时重新启动它。
	旧版：https://downloads.mysql.com/archives/community/  最新版在官网下载https://dev.mysql.com/downloads/mysql/  rpm包：https://repo.mysql.com/yum
	1.从官网下载软件包，解压并移动到指定位置--貌似不用编译
	2.添加环境变量
	3.创建数据库目录
		mkdir -p /usr/local/mysql/{data,tmp,binlog,log,conf}   &&  touch /usr/local/mysql/log/mysqld-error.log
	4.创建配置文件
		cat conf/my.cnf
			[mysqld]
			port=3333														 #这里将端口修改是为了确认配置没问题
			user=mysql
			basedir=/usr/local/mysql
			datadir=/usr/local/mysql/data
			#socket=/usr/local/mysql/tmp/mysql.sock symbolic-links=0		 #默认是在/tmp下的，如果配置了，服务端在连接的时候要使用-S选项指定sock位置
			skip-mysqlx                               						 #5.7.12 之后新增了X plugin，不加载X plugin，这个会增加一个端口，是类似MongoDB的服务
			log-bin = /usr/local/mysql/binlog/mysql-bin                      #开启binlog日志，不写路径，默认在data数据目录下
			binlog_format = ROW
			binlog_expire_logs_seconds = 100000
			server-id = 1
			slow_query_log = 1                    								#开启慢查询
			long_query_time = 1                  				 				#慢查询时间 超过1秒则为慢查询
			slow_query_log_file = /usr/local/mysql/log/localhost-slow.log       #慢查询日志位置
			skip-name-resolve                    				 				#禁止MySQL对外部连接进行DNS解析 DBA
			max_connections = 2000   										    #MySQL的最大连接数
			default-storage-engine = InnoDB
			innodb_thread_concurrency = 16     								    #innodb线程并发数
			#[mysqld_safe]	 													#有这个配置的话，需要启动改服务才会使下面的配置生效，不启动该服务，需要删除该配置
			log-error=/usr/local/mysql/log/mysqld-error.log
			pid-file=/usr/local/mysql/tmp/mysqld.pid
	5.创建普通用户，并给与权限		
	6.初始化/空密码(--initialize换成该选项会生成临时密码并在终端输出/有的说会在日志里出现)
		mysqld --initialize-insecure --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --user=mysql    
	7.mysqld --verbose --help  | head -30     								 #帮助
	8.启动：su mysql -s /bin/bash -c "mysqld --defaults-file=/usr/local/mysql/conf/my.cnf --user=mysql &" (defaults-file要在第一个参数)     或者使用脚本启动 cp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysql.server(脚本默认路径是/usr/local，要是情况而修改)  
	9.安全检查：./bin/mysql_secure_installation
		
	


mysql db_name -hlocalhost -uroot -C -P3306 [-S /path/mysql.sock] [-E] -e "select database()"  
select @@[global|session].system_var_name    #@@后面带的是准确的变量名称
show status\G;  #运行时的转台变量
show variables like '%c%'  #查找特定变量
create table test1(id int primary key auto_increment, name varchar(55) not null default lin,index ind_name(name))engine=InnoDB auto_increment=2 default charset=utf8; #创建表
status;             #查看当前连接状态
create database if not exists textdb default character set utf8;
show table status [like "user"]\G;						  	#查看表简要信息
desc user;
show create table user\G; 									#查看表创建语句
create table testtab1 like test1;							#复制表结构(包括约束条件)
show index from test1;										#查看表索引
create table test3 select * from test1;					#创建表数据(不包括约束条件)
drop table test1;										#删表
delete from somelog where user = 'jcole';				#删表数据
insert into test1 value(3,"lin");						#插入表数据
alter table table_name rename as/add/drop/[change/modify]    #表名重命名/添加字段/删除字段/[修改字段类型/修改字段类型]
create view test2 as select * from test1;                  #创建视图

select count(num),gender from students group by gender;   #分组的目的往往时对分组后的数据进行聚合操作，如果想要对分组后的数据再次过滤，可以使用having关键字
select * from tb1 limit 3;                              #显示前三行
	where name like 't_';                               #条件，in /not in  like rlike  between  not between  !=
	order by (desc asc)                                 #降序/升序
多表查询：cross join(可以忽略) inner join(同时符合) left join   right join     联合查询：union  union all   full join
子查询原则:    1.一个子查询必须放在圆括号中。2.将子查询放在比较条件的右边以增加可读性。

#http://www.zsythink.net/archives/category/%e5%ad%98%e5%82%a8/
show variables like '%query_cache%';         #查询缓存,开/关/按需(关键字)，查询语句区分大小写
show status like 'Qcache%';  show status like 'Com_select%';

show engines; #引擎   innodb_file_per_table（独立表空间）

事务：ACID     redo log实现ACID的原子性(A)(物理日志redologfile)  undo log数据修改前的备份(逻辑日志) 
				一个重做日志组（log group）中有多个重做日志文件(redo log file) redo log写入第一个redo log file 中 
				redo log存储于重做日志文件中，undo log则不同，undo存放在数据库内部的特殊段中，这个段被称为undo段（undo segment），undo段位于共享表空间中。
				过程:事务开始 -- log buffer -- os buffer -- log file

一致性非锁定读：提高了并发性，某行被施加了排他锁，其他行需要读取时，不用等到锁解除，会去读取快照(undo段)
事务隔离级别：通过锁来实现的（start transaction[with consistent snapshot]/begin）
 串行化：不会出现幻读，因为没使用一致性非锁定读，A未提交前B是看不到的
 可重读：A事务提交了，B事务未提交则无法看到修改，提交了才能看到修改(幻读，在可重读基础上，B未提交但是却更新了，导致跳过A的提交(因为看不到A的提交))
 读提交：A事务提交了，B马上就能看到，会出现幻读和不可重读
 读未提交：会出现脏读
	脏读：当前事务可以查看到别的事务未提交的数据
	幻读：侧重新增和删除，资源莫名多了或少了
	不可重读：侧重修改，同一资源莫名的改变了

日志：错误日志(log_error+log_warnings)  查询日志(general log/log_output)  慢查询日志(slow_query_log+mysqldumpslow)  
二进制日志(log_bin)：mysqlbinlog(tool) 可用于时点恢复  模式：statement/row/mixed 记录语句不同  
	中继日志(relay log)  事务日志(redo log)

数据的一致性：通常指关联数据之间的逻辑关系是否正确和完备，保证数据一致性的方法：加锁/快照
	快照：处于可重读的隔离级别下(事务中的第一个查询语句执行时，快照建立)，将备份操作放在一个单独的事务中(不进行更新，是不会出现幻读的)
数据库的一致性：数据库从一个一致性状态变到另一个一致性状态	

备份：全量备份，差异备份，增量备份，通过select语句进行部分备份(outfile/infile)，热备，温备，冷备，逻辑备份，物理备份
mysqldump(逻辑备份):1.浮点型数据，会出现精度丢失 2.串行，效率低  3.对myisam只支持温备
	将数据查找出来并转换成对应的insert语句，默认重定向到屏幕，可重定向到文件
mysqldump -uroot -hlocalhost -p db_name table_name ...   #备份多张表
mysqldump -uroot -hlocalhost -p --databases zsythink test  #备份多个库[--all-databases]
mysqldump -uroot -hlocalhost -p -d db_name [table_name...]  #备份所有表/一张表的表结构
	
xtrabackup(物理备份)：备份page数据块
	innodb逻辑结构：表空间(tablespace) 段(segment) 区(extent) 页(page) 行(row)
	
xtrabackup: LSN是一个全局递增的号码	，每次对page中的记录进行修改，都会有对应的lsn码,通过LSN，实现对innodb表的增量备份
	xtrabackup在备份开始时，同时运作两个线程，一个线程负责备份innodb中的page，另一个线程负责备份innodb的事务日志（redo log），事务日志都会被xtrabackup记录到自己的日志文件中
	备份结束后，我们会得到两份文件，一份是不可用的备份文件，一份是备份时的事务日志，备份文件之所以不可用，是因为有一部分不确定的数据可能在事务日志中，而且热备过程中数据也可能会发生改变，所以我们要通过这两份文件，制作出一份可用的备份文件，
	事务日志文件中已经提交的事务需要replayed，未提交的事务需要roolback，整个过程类似于mysql崩溃后恢复的过程，这个过程在xtrabackup中被称为"prepare"，"prepare"操作保证了备份出的数据的一致性，没有经过prepare的备份数据是不可用的，我们可以理解为如果想要得到一个可用的备份，则需要进行这些所谓的"准备"工作或者所谓的"数据恢复"的工作。
	
MySql--三种注释写法(对bangde注释)
		1.#bangde    2. -- bangde    3. /*bangde*/
	


SELECT DISTINCT  < select_list >
FROM  		< left_table > < join_type >
JOIN 		< right_table > 
ON 			< join_condition >
WHERE  		< where_condition >
GROUP BY  	< group_by_list >
HAVING  	< having_condition >
ORDER BY    < order_by_condition >
LIMIT 	    < limit_number >	

1:FROM <left_table>
2:ON <join_condition>
3；<join_type> JOIN <right_table>
4：WHERE <where_condition>
5：GROUP BY <group_by_list>
6：HAVING <having_condition>
7：SELECT
8；DISTINCT <select_list>
9：ORDER BY <order_by_condition>
10：LIMIT <limit_number>	
	
	
	
    c/s            MongoDB  MySQL   Oracle	 Informix	D B 2
Database Server	   mongod	mysqld	oracle	 IDS	    DB2 Server
Database Client	   mongo	mysql	sqlplus	 DB-Access	DB2 Client	

顺序IO是指读取和写入操作基于逻辑块逐个连续访问来自相邻地址的数据	
mysql的日志文件都是IO顺序插入的,顺序插入的优点是速度快(磁头几乎不用换道或换道时间极短).缺点是会产生磁盘碎片	
binlog日志：记录所有的逻辑操作--insert/update/delete  用于恢复数据。事务提交的时候记录
redo log日志：记录物理操作--某页哪个数据修改了。保证持久性,用于数据库突然宕机，脏数据的恢复	。事务开始时记录
undo log日志：记录与binlog日志想法的逻辑操作，用于回滚。保证原子性：即要么全执行要部全不执行	
	
	
################################################################################################

mysql：
   生产应用mysql用户，尽量不用delete操作
   有条件情况下，做一个延迟一小时的从库
   
备份脚本：所有，库级别，表级别
回滚脚本

一主双从：主库写入(有索引写入慢)，一个从库建立索引用于查找，一个用于灾备
#主主
MHA：高可用

中间件 /  分布式
tidb:https://gitee.com/pingcap/tidb

数据库转储：
     mysqldump去掉drop table语句
	 删除的时候，按id，分批删除，防止主从延迟

如果一张表有很多记录，则添加会影响很大：用工具mysql-pt添加字段


################################################################################################

https://www.bilibili.com/video/BV12b411K7Zu?p=149
https://www.cnblogs.com/kevingrace/p/10482469.html

DML：
select [查询列表 as 别名⑦] from [表名 as 别名①]或者[表1 别名 连接类型 join 表2 别名② on 条件③ [连接类型 join 表2 别名 on 条件]...] [where 分组前筛选条件④] [group by 分组列表⑤] [having 分组后筛选⑥] [order by 排序列表⑧] [limit offset,size⑨];
#子查询：本身就是单独查询，是可以执行的  按子查询出现的位置：1.select后面 2. from后面  3. where或having后面  4.exists后面(相关子查询，结果为1或0)        不同位置需要结果集(标量子查询，列子查询，行子查询，表子查询)不同
	#子查询适用于，条件是查询语句。分析：查询公司工资比A高的人 ---> ①.查询出A工资  ②.查询工资>①
	查询列表: 多个用,隔开   #显示内容
		表中字段：字段用``转义，区别关键字和字段
		常量值：100  'string'
		表达式: 100%98
		函数: VERSION()
	  distinct: 去重
	  + :  1.运算符 2.字段组合显示  
	  
	别名：显示名称
	
	分组前筛选条件：数据源是原始表
	    条件表达式：>< = != <> >= <=    #不能判断null
		逻辑表达式: &&和and ||和or !和not
		模糊查询：like ：        1.% 0-n个字符  2._ 一个字符  #使用\转义  
		          between and ： id between 100 and 120   
				  in:            id in (1,3,5)       #数据类型需要一致           
				  is null:       id is null
	
	分组后筛选：分组函数作为条件，数据源是分组后的结果集
	
	排序列表：id asc , age desc;  #支持单个字段和多个字段逗号隔开，表达式，函数，别名

    分组列表：id , age;           #支持单个字段和多个字段逗号隔开，表达式，函数，字段别名

	连接类型：inner  full            #inner显示共同有的，full显示全部
			  left(左为主表) right(右为主表)   #查询结果为主表中的所有记录，从表有匹配则显示，没匹配则显示null
			  cross: 新标准的笛卡尔乘积



函数：
	字符函数：
		length('张zhang')
		upper('zhang')
		lower('ZHANG')
		concat('字段','常量','函数')     #拼接
		substr('zhang',2,3)				 #截取
		lpad rpad('zhang',2,"*")         #填充  
		replace("zhang","a","b")
		
	数字函数：
		round() 四舍五入
		ceil()  向上取整
		floor() 向下取整
		truncate() 截断
		mod()      取余
	
	日期函数：
		now()
		cupdate()
		curtime()
		year()
	
	其他：
		version()
		database()
		user()
		
	流程控制函数：返回一个值
		if: select if(10<5,"大","小");
		case:
	
	分组函数：
		sum avg max min 
		count：统计结果行数

旧版本的多表查询：
笛卡尔乘积：结果集为A表行数*B表行数，是连接查询的一种特例(没有添加筛选条件)
select girlname,boyname from boys,girls [where girls.girl_id=boys.boy_id]


连接查询join on：多表查询但表之间有关系，是一个语句
子查询：结果集是动态实时用语句查询出来的，不同部分是单独的语句，可执行并得出结果集
联合查询union：多表查询但表之间没有关系，不同部分是单独的语句，可执行并得出结果集


插入insert：支持多列多表更新
更新update：支持多表更新
删除delete：支持多表更新


DDL：针对库和表
	create  
	alter
		alter table 表名 modify column 字段名 字段类型 新约束   	#修改已存在列(列级约束)
		alter table 表名 add [constraint 外键名字] foreign key [外键字段] references 父表(主键字段);	#新添加一列(表级约束)
	drop
	#复制表结构，部分表结构，表数据，部分表数据

数据类型：
	数值：
		整型：有无符号    超出以边界值填充    zerofull以0填充位数  
		浮点型
	文本：
	枚举：
	日期：

约束：
	类型：
		not null : 非空
		default：默认值
		primary key：主键，唯一且非空，只能一个，允许组合
		unique：唯一，可以为空，可以有多个，允许组合
		foreign key：外键，被外键的列需要是key(primary或者unique)
			#语法：foreign key [本表外键字段] references 父表(主键字段);
		check：mysql不支持，检查输入值
		
	列级约束：在列后面直接添加						  #不支持外键，不可以起约束名
	表级约束：[constraint 约束名] 约束类型(字段名)    #不支持非空not null 和 默认default ，可以起约束名但对主键无效
	例子：
		create table mytest(
			id int primary key,    #列级约束
			age int default 18,
			constraint age_uq unique(age)  #表级约束
		);
	
	主从表删除：原则上是先删主表再删从表。但是可以用 "级联删除" "级联置空"删除
	
标识/自增长列：可以不用手动的插入值，系统提供默认的序号值
	auto_increment    #show variables like "%auto_increment%"  还可以设置步长
	#1.只能是数值型，至多一个，需要是key

主从表删除：原则上是先删主表再删从表。但是可以用 "级联删除" "级联置空"删除
	
TCL：事务：一个或一组sql语句组成一个执行单元，这个执行单元要么全部执行成功，要么全部执行失败	
	事务管理特性：
		acid：atomicity原子性(执行单元不可分割)  consistency一致性(A+B转账前(一致性状态)后(另一一致性状态)总余额不变)
			isolation隔离性(不同事务之间干扰程度，由隔离级别决定)     durability持久性(事务一旦被提交成功，对数据库中数据的改变就是永久性的)
	分布式系统的CAP理论：
		一致性（Consistency）：分为强/弱/最终一致性三类
		可用性（Availability）：可用性通常情况下与分布式数据冗余，负载均衡等有着很大的关联。
		分区容错性（Partition tolerance）：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。

	步骤：
		1.开启事务
			set autocommit=0;   #关闭自动提交
			start transaction;  #开启事务，可省略
		2.编写食物中的sql语句
		3.结束事务
			commit  	#提交事务
			rollback	#回滚事务
		#savepoint 设置保存点，在回滚的时候可以只回滚保存点后的操作
		
		
	事务的隔离级别：1.未提交读Read uncommitted  2.已提交读(语句级)Read committed   3.可重复读(事务级)Repeatable read   4.可序列化(最高级的事务级)Serializable
	show variables like "tx_isolation";		
	并发事务处理带来的问题：
		更新丢失(AB同时修改同一数据，导致先更新的被后更新的覆盖(AB都读到5，但A先修改为6，B仍以5为数据进行修改))  
		脏读：A更新时，B查看时是更新的数据(有可能回滚)
		不可重复读：A更新提交前和后，B查看两次分别是更新前(不会脏读)和更新后的数据
		幻读：A更新未提交，B插入一行并提交，A提交发现更新多了一行


视图：虚拟表，和普通表一样使用，但是通过相关表动态生成的数据
	步骤1：创建 create [or replace] view myview as 查询语句     2. select * from myview
		   修改 alter view myview as 查询语句
		   删除：drop view 视图名,...
	#简单视图可以更改，但很多不能更新(分组函数，group by，distinct,having,union,join,常量...)



变量：
	系统变量：系统提供的  
		语法： 
			查看1: show global|[session] variables [like "%char%"]
			查看2：select @@global|[session].系统变量
			赋值1：set global|[session] 系统变量名 = 值
			赋值2：set @@global|[session].系统变量=值
		分类：	
			全局变量：针对所有会话
			会话变量：针对当前会话
	自定义变量
		用户变量：针对当前会话,都有一个@
			声明并初始化：
				set @用户变量名=值 或 set @用户变量名:=值 或 select @用户变量名:=值
			赋值：
				1.set @用户变量名=值 或 set @用户变量名:=值 或 select @用户变量名:=值
				2. select 字段 into @变量名 from 表
			查看：
				select @用户变量名
		局部变量：begin end中的第一句
			声明：
				declare 变量名 类型;
				declare 变量名 类型 default 值;
			赋值：
				1.set 局部变量名=值 或 set 局部变量名:=值 或 select @局部变量名:=值
				2. select 字段 into 局部变量名 from 表
			查看：select 局部变量名
			
存储过程：一组预先编译好的sql语句的集合，适合批量操作数据
	优点：1.提高代码重用性  2.简化操作  3.减少编译次数和连接次数
	创建语法：
		create procedure 存储过程名(参数列表)
		begin
			存储过程体(一组合法的sql语句)
		end
	参数列表包含三部分：参数模式 参数名 参数类型  例：IN stuname varchar(20)
		参数模式：
			IN: 调用时传入
			OUT: 返回值
			INOUT: 即在调用时需要输入，又会作为返回值输出
	如果存储过程体仅一句sql语句，begin end可省略
	存储过程的结尾使用delimiter重新设置
	存储过程体中每条sql语句结尾要求加;
	
	调用：call 存储过程名(实参列表)
	查看：show create procedure 存储过程名
	删除：drop procedure 存储过程名
	例子：
		创建：
			DELIMITER $$
			create procedure mycunchu(IN beautyName varchar(20),OUT boyName varchar(20))
			begin
				#declare result int default 0; 声明局部变量
				select bo.boyName into boyName      #将结果赋值给out变量，多个out用,隔开，即into boyName,...
				from boys bo
				inner join beauty b on bo.id = b.boyfriend_id
				where b.name=beautyName
				#select if(result>0,'成功','失败') 调用
			END$$
			DELIMITER ;
		调用：
			call myfun('小赵',@bName)
			select @bName
	#如果是INOUT参数模式，需要传入有值的变量@var ,这样既能传入又能传出		

函数：
	和存储过程的区别
	有且仅有1个返回，适合处理数据
	创建：
		create function 函数名(参数列表) returns 返回类型
		begin
			函数体   #和存储体使用一样的
		end
	参数列表：参数名 参数类型
	函数体中有return语句
	调用：select 函数名(参数列表)
	查看：show create function 函数名
	删除：drop function 函数名
	
流程控制结构：
	顺序结构：程序代码依次执行
	分支结构：程序有选择的执行 if  case
	循环结构：程序在满足一定条件基础上，重复执行一段代码  while  loop  repeat
	语法：
		[标签:]while 条件 do
			执行语句;
			if 条件 then leave 标签;       #使用标签进行循环控制
			end if;
		end while 标签;
	
	
	
	
优化：	

expain：语法：explain sql语句;
		1.表的读取顺序  2.数据读取操作的操作类型  3.哪些索引可以使用  4.哪些索引被实际使用  5.表之间的引用  6.每张表有多少行被优化器查询
		2.各字段解释
		  | id   | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra |
		    id：id相同，从上往下顺序执行，id不同，值越大，优先级越高，越先执行   # null表示从临时表取数据  <derived2>:id为2的衍生表(临时表：会增加负担，如两个数据交换) 
			  select_type：1.simple    2.primary    3.subquery   4.derived   5.union   6.union result ...
			  table：
		    type：    NULL       >   system   >  const    >     eq_ref       >          ref             >    range    >     index  >   ALL        #最好是ref
			      不用查表/索引	   一行数据    主键=常量 唯一性索引扫描(主键=主键) 非唯一性索引扫描(=多值)  条件是范围     索引扫描   全表扫描
			  possible_keys：指出MySQL能使用哪个索引在表中找到记录(如果是覆盖索引，则不会显示在这里)
		    Key：实际用到的索引(null为没建立索引或者索引失效)
			key_len:实际用到的索引条件的多少(索引条件相同，值相同)，长度越短效率越高，与精度成反比 
			  ref:显示索引的那一列被使用(值越多精度越高),格式为"库.表.字段"，如果可能的话，是一个常数(const)，哪些列或常量被用于查找索引列上的值
			  rows：越小越好，表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数(每张表有多少行被优化器查询)
			extra:包含不适合在其它列中显示但十分重要的额外信息
				Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”（很危险）            #order by要么不建索引，要么和索引的顺序和个数一致 Seq_in_index
				Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询（最危险） #group by或order by要么不建索引，要么和索引的顺序和个数一致 Seq_in_index
				Using index：查询字段从索引中就能够取得，不必读取数据行(覆盖索引，相当好)
				Using where：去表里检索(用于查询列表字段)
				Using join buffer：使用了连接缓存，配置文件增加buffer
				impossible where:where子句的值总是false，不能用来获取任何元组(类似where 1=2,这说明条件有问题)
	

索引原则：根据查询条件where建立索引
	1.左连接加右表(左表是全显示的，关键是右表)，右连接加左表
	
	2.全值匹配:常量(=) 并且索引都用上
	3.使用!=或者<>的时候无法使用索引会导致全表扫描
	4.存储引擎不能使用索引中范围条件 > 或 < 右边的列（中间条件使用范围条件,范围条件以后字段就无法索引）
	5.is null , is not null 也无法使用索引
	6.少用or，用它连接时会索引失效	
	7.like 使用通配符('%abc...'不要是开头) 索引失效，会变成全表扫描的操作 (可以使用覆盖索引解决)
	
	8.最佳左前缀法则(覆盖索引)：索引了多列，要遵守最左前缀法则，即查询条件从索引的最左前列开始并且不跳过索引中的列，并且只包含=的查询
	9.尽量使用覆盖索引：少用select * ,查询字段与索引字段一致或顺序一部分
	
	10.不在索引列上做任何操作(计算/函数/自动or手动类型转换..)会导致索引失效而转向全表扫描
	11.字符串不加单引号索引失效：即char/varchar要需要加'',原因是在索引上做了操作(自动类型转换)  #会导致行锁变成表锁，阻塞直到提交


创建：create index idx_article_ccv on article(id,comments,views);
显示：show index from article;                                        # 按Seq_in_index进行排序，即1排序完成再排序2...，保证所查字段排序与索引排序一致
删除：drop index idx_article_ccv on article
创建：alter table 'book' add index u('card');

索引作用：查找和排序
索引(排序(按Seq_in_index进行排序)+检索/查询)能高效获取数据的数据结构。目的在于提高查询效率(B+树/多路搜索树)      #按Seq_in_index从小到大挨个关联进行排序)+检索/查询 利用索引这句话是本质
	索引分类：1.单值索引   2.唯一索引   3.复合索引		索引结构：1.Btree索引  2.Hash索引   3.full-text全文索引   4.R-Tree索引
	在数据之外，数据库系统维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用(指向)数据
		索引一般也很大，不能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上
		索引依据：1.频繁查找的字段应该建立索引  2.主键自动建立唯一索引  3.where条件里用不到的字段不建立索引   4.高并发下倾向于建立组合索引
				  5.查询中排序的字段，排序字段若通过索引去访问将大大提高速度  8.查询中统计或分组字段
				  1.经常更新的数据不适合做索引   2.表数据太少  3.重复内容多的数据列
		索引的建立根据业主而变化，是一个持续的过程
			优势：降低io和cpu消耗，提高效率和降低成本  缺点：增加存储空间，降低更新操作
		重构索引：
		覆盖索引：所查数据只需从索引中便能获取，即所查字段少于或等于复合索引个数 并且顺序一致



pt-query-digest: https://www.cnblogs.com/zhoujinyi/p/12374565.html	https://www.percona.com/doc/percona-toolkit/3.0/index.html
分析诊断工具：
	1.慢日志的开启并捕获(调优时开启)
	2.explain + 慢日志查询 
	3.show profile查询sql在mysql服务器里面的执行细节和生命周期情况
	4.sql数据库服务器的参数优化
	5.show full processlist\G;


永远小表驱动大表(先执行少的)：查询总次数一定情况下：使连接次数最少，一次连接查询次数最多
	select * from A where id in (select id from B)             			 #返回真正的数据
		等价于 1.for select id from B  2.for select * from A where A.id = B.id
		当B表的数据集必须小于A表的数据集时，用in优于exists
	select * from A where exists (select 1 from B where B.id = A.id)     #1代表常量，可以是别的。返回True/False 
		等价于 1.fro select * from A  2.for select * from B where B.id = A.id
		当A表的数据集必须小于B表的数据集时，用exists优于in
	A表和B表的ID字段应建立索引
exists语法：将主查询的数据，放到子查询中做条件验证，根据验证结果(True/False)来决定主查询的数据结果是否得以保留


order by子句：遵照索引建的最佳左前缀(单独与where)
mysql有两种排序，尽量使用index方式排序，避免使用FileSort方式排序            
using index 和 filesort，filesort有双路排序(扫描两次磁盘)和单路排序(一次io,在内存排序) 
#单路排序有可能一次性取不完，即sort_buffer_size(会导致创建临时文件)和max_length_for_sort_data太小
			  	
group by实质是先排序后进行分组，准找索引的最佳左前缀
where 高于 having ，能现在where限定的条件不要去having限定


慢日志：show variables like "%slow_query_log%";
		set global slow_query_log=1;  					#开启
		show variables like "long_query_time%";   		#大于该秒数记录慢日志，重开会话才能看到修改值 , select sleep(n);
		show global status like "%Slow_queries%";  	#查询当前系统中有多少条慢查询日志
慢日志分析工具：mysqldumpslow
	-s:排序方式 = "c:访问次数   l:锁定时间  r返回记录  t：查询时间  al:平均锁定时间  ar:平均返回记录数  at:平均查询时间"  
	-t:返回记录数  -g:搭配正则，忽略大小写 
	得到返回记录集最多的10个sql 						 mysqldumpslow -s -r -t 10 filename.log
	得到访问次数最多的10个sql      						 mysqldumpslow -s c -t 10 filename.log
	得到按照时间的前10条里面含有左连接的查询语句		 mysqldumpslow -s t -t 10 -g "left join" filename.log

批量数据脚本
	函数和存储过程都是用sql脚本语言写的编程
		区别：函数有返回值，存储过程没有返回值
	show variables like 'log_bin_trust_function_creators';

show profile:参数默认是关闭状态，并保存最近15次的运行结果
	1.show variables like 'profiling';
	2.set profiling=on;
	3.运行sql
	4.查看结果：show profiles;               #获取Query_ID
	5.show profile cpu,block io,memory for query  Query_ID;  #诊断sql:能得到整个sql语句执行周期
	6.重要指标
		1.converting HEAP to MyISAM     #查询结果太大，内存不够用了，往磁盘上搬了
		2.creating tmp table            #创建临时表 1.拷贝数据到临时表 2.用完再删除(order by)
		3.copying to tmp table on disk  #把内存中临时表复制到磁盘，危险！
		4.locked

全局查询日志：太耗费资源，只能在测试环境使用（模拟一段时间内的sql执行，出错的过程）
	general_log = 1                    #开启,之后编写的sql语句，将会记录到mysql库里的general_log表
	general_log_file = /path/logfile   #记录日志文件的路径
	log_output = file				   #输出日志



锁是计算机协调多个进行或线程并发访问某一资源的机制
分类：从对数据操作的类型：读锁(共享锁)和写锁(排它锁)
	  从对数据操作的粒度：行锁和表锁（介于两者之间的页锁,会出现死锁）
	依据：开销，加锁速度，死锁，粒度，并发性能
	行锁：偏向innodb存储引擎，开销大，加锁慢，会出现死锁，锁定粒度最小，发生锁冲突的概率最低，并发度也最高
	表锁：偏向myisam存储引擎，其它和行锁相反
	Myisam的读写锁调度是写优先，因为写锁后，大量更新会使查询很难得到锁，从而造成永远阻塞。因此不适合做写为主表的引擎	
    innodb和myisam的不同点：1.支持事务(transaction)  2.采用了行级锁
语法:1.lock table 表名字 read(write)   2.unlock tables;
	读锁：session1 为 table1 添加了read lock(读锁) 
			那么：session1只能读table1，不能修改table1,也不能读写别的table(无锁状态)
				  非session1，能读不能写(阻塞)table1，能读写其它的table
	写锁：session1 为 table1 添加了写锁
			那么：session1可读可写table1,但是不能读写其它的table
				  非session1，读写table1会一直阻塞，能读写其它的table

分析表锁：
	查看锁：show open tables;  (0表示没锁)
		show status like "table%";
			| Table_locks_immediate | 45   #产生表级锁定的次数，表示可以立即获取锁的查询次数，每立即获取锁值加1
			| Table_locks_waited    | 0    #出现表级锁定 争用而等待的次数(不能立即获得锁的次数)，此值高则说明存在着较严重的表级锁争用情况
	
	
索引失效行锁可能变表锁(varchar类型不加'')
间隙锁：当使用范围条件而不是相同条件检索数据，并请求共享或排它锁时，innodb会给符合条件的已有数据记录项加锁，对于键值在条件范围内并不存在的记录，叫做间隙(GAP)
	实例：1.update test set b='06' where a>1 and a<6;   2.insert into test values(2,'2000');   #a=2在1执行的时候是不存在的，但执行2的时候还是会被阻塞

锁定一行：select * from test where a=8 for update;    #commit之后，锁会自动释放

分析行锁：
	innodb存储引擎实现了行级锁定，性能消耗比表级锁高，但并发处理能力远由于Myisam表级锁定，但若使用不当，行锁变表锁，就很严重
		show status like 'innodb_row_lock%';
			| Innodb_row_lock_current_waits | 0     |   当前正在等待锁定的数量
			| Innodb_row_lock_time          | 0     |   从系统启动到现在锁定总时间长度
			| Innodb_row_lock_time_avg      | 0     |	每次等待所花平均时间
			| Innodb_row_lock_time_max      | 0     |	从系统启动到现在等待最长的一次所花时间
			| Innodb_row_lock_waits         | 0     |	系统启动后到现在总共等待的次数

总结：
	1.尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁(varchar类型加'')
	2.合理设计索引，尽量缩小锁的访问
	3.尽可能减少检索条件，避免间隙锁
	4.尽量控制事务大小，减少锁定资源量和时间长度
	5.尽可能低级别事务隔离


主从复制：master可以有多个slave，每个slave只有一个master，每个slave都有唯一一个服务器id
主：配置路径log_bin(master将sql操作写入二进制文件叫做'二进制事件')
	配置路径log_err / basedir(根目录) / tmpdir / datadir(数据库目录) / read-only 
		    binlog_ignore-db(设置不要复制的数据库) / binlog-do-db(需要复制的目录)
从：唯一id / log-bin(日志)	
	
	
	
	
	
	
	