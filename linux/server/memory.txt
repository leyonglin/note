
 free -th/lh
 
 清除cache写进硬盘：
 sync; echo 1 > /proc/sys/vm/drop_caches     #仅清除页面缓存
 sync; echo 2 > /proc/sys/vm/drop_caches     #清除目录项和inode
 sync; echo 3 > /proc/sys/vm/drop_caches     #清除页面缓存，目录项和inode
 关闭swap：
 nohup swapoff -a &>/dev/null &
 
 vmstat：  vmstat -w 1(间隔) -S(指定单位) m [-d/-a]
 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
  r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 procs(进程)    r：运行进程数   b等待资源/io数
 memory(内存)   swpd：交换内存使用   物理内存free  buff/cache
 swap(交换内存) si：从磁盘换入的交换内存量    so：交换内存换入磁盘量  
 io(磁盘读写)   bi：每秒写入的块数   bo：每秒读出的块数
 system(系统)   in：每秒中断数,包括时钟中断。 cs：每秒上下文切换数。
 cpu(中央处理器)us:用户进程使用   sy：内核进程使用   wa：io等待时间  id：空闲时间   st(从虚拟机器偷来的时间)
 -d 磁盘模式：
 total：成功完成的读取总数   merged合并:分组读取(产生一个输入/输出)   sectors:扇区读取成功   ms:读取花费的毫秒数
 cur当前: 进行中的读写    s:读写花费的秒数
 
 查看某个进程使用的swap：awk '/^Swap:/ {SWAP+=$2}END{print SWAP" KB"}' /proc/$(pid)/smaps  
 列出进程使用的交换分区：1.过滤大于100的：cmd | awk '$0>100'       2. 加法运算：BEGIN{a=0}{a=a+$2}END{print a}
 for i in $(cd /proc;ls | grep "^[0-9]" | awk '$0>100'); do awk '/Swap:/{a=a+$2}END{print '"$i"',a/1024"M"}' /proc/$i/smaps;done| sort -k2nr | head
   netstat -antp | grep pid  查看连接状态
   awk  '{ip[$1]++} END{for(i in ip) {print ip[i],i}}' ip.txt | sort -nr 
   netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
   awk [ 选项] ' BEGIN{ 指令} { 指令} END{ 指令} ' 文件
   
 内存--内存储器---随机存储器（RAM）
 DMA(Direct Memory Access，直接内存存取) 是所有现代电脑的重要特色，它允许不同速度的硬件装置来沟通，而不需要依赖于 CPU 的大量中断负载
 只读存储器（ROM）
 物理存储器是指实际存在的具体存储器芯片。如主板上装插的内存条和装载有系统的BIOS的ROM芯片，显示卡上的显示RAM芯片和装载显示BIOS的ROM芯片，以及各种适配卡上的RAM芯片和ROM芯片都是物理存储器。
 存储地址空间是指对存储器编码（编码地址）的范围。所谓编码就是对每一个物理存储单元（一个字节）分配一个号码，通常叫作“编址”。分配一个号码给一个存储单元的目的是为了便于找到它，完成数据的读写，这就是所谓的“寻址”（所以，有人也把地址空间称为寻址空间）。
 地址空间的大小和物理存储器的大小并不一定相等
 其地址总线为32位，因此地址空间可达2的32次方，即4GB。但是我们一般使用的一些32位操作系统例如windows xp、却最多只能识别或者使用3.25G的内存(24位地址线，它可寻址16MB的地址空间)
 CL延迟:CL反应时间是衡定内存的另一个标志。CL是CAS Latency的缩写，指的是内存存取数据所需的延迟时间，简单的说，就是内存接到CPU的指令后的反应速度。一般的参数值是2和3两种。数字越小，代表反应所需的时间越短
 内存主频和CPU主频一样，习惯上被用来表示内存的速度，它代表着该内存所能达到的最高工作频率。内存主频是以MHz（兆赫）为单位来计量的。内存主频越高在一定程度上代表着内存所能达到的速度越快
 奇/偶校验（ECC）是数据传送时采用的一种校正数据错误的一种方式，分为奇校验和偶校验两种。
 
 内存容量(多少)，内存速度(频率)，延时周期(当CPU需要内存中的数据时，它会发出一个由内存控制器所执行的要求，内存控制器接著将要求发送至内存，并在接收数据时向CPU报告整个周期，从CPU到内存控制器，内存再回到CPU)
 内存带宽=总线宽度(双通道)×总线频率×一个时钟周期内交换的数据包个数。内存的容量决定“仓库”的大小，而内存的带宽决定“桥梁”的宽窄
 内存控制器是计算机系统内部控制内存并且通过内存控制器使内存与CPU之间交换数据的重要组成部分。内存控制器决定了计算机系统所能使用的最大内存容量、内存BANK数、内存类型和速度、内存颗粒数据深度和数据宽度等等重要参数，也就是说决定了计算机系统的内存性能，从而也对计算机系统的整体性能产生较大影响。
 集成内存控制器(节约时间)就是在CPU的基板上内置一个内存控制器
 前端总线FSB：
 
 虚拟内存VIRT，物理内存RES，共享内存SHR
 虚拟内存：凡是程序运行过程中可能需要用到的指令或者数据都必须在虚拟内存空间中。
 驻留内存：是指那些被映射到进程虚拟内存空间的物理内存
 
 在计算机系统中按其所连接的对象，总线可分为： 片总线，又称器件级总线，它是中央处理器芯片内部的总线。内总线，又称系统总线或板级总线，它是计算机各功能部户之间的传输通路，微型计算机总线通常称为内总线。外总线，又称通信总线，它是计算机系统之间，或者是计算机主机与外围设备之间的传输通路
 总线（Bus）是计算机各种功能部件之间传送信息的公共通信干线，它是由导线组成的传输线束， 按照计算机所传输的信息种类，计算机的总线可以划分为数据总线、地址总线和控制总线，分别用来传输数据、数据地址和控制信号。总线是一种内部结构，它是cpu、内存、输入、输出设备传递信息的公用通道，主机的各个部件通过总线相连接，外部设备通过相应的接口电路再与总线相连接，从而形成了计算机硬件系统。在计算机系统中，各个部件之间传送信息的公共通路叫总线，微型计算机是以总线结构来连接各个功能部件的
 总线可同时传输的数据数就称为宽度（width），以比特为单位，总线宽度愈大，传输性能就愈佳。总线的带宽（即单位时间内可以传输的总数据数）为：总线带宽 = 频率 x 宽度（Bytes/sec）
 共享型的数据传送设备，但任一时刻通常只能有一对设备参与数据传输。并行总线对n位二进制信息用n条传输线同时传送，其特点是传输速度快，但系统结构较复杂，它用于计算机系统内的各部件之间的连接；串行总线对多位二进制信息共用一条传输线，多位二进制信息按时间先后顺序通过总线，它的特点是结构简单，但其传输速度较慢
 PCI（Peripheral Component Interconnect）总线是当前最流行的总线之一，它是由Intel公司推出的一种局部总线。它定义了32位数据总线，且可扩展为64位。PCI总线主板插槽的体积比原ISA总线插槽还小，其功能比VESA、ISA有极大的改善，支持突发读写操作，最大传输速率可达132MB/s，可同时支持多组外围设备。
 总线按功能和规范可分为五大类型:
 数据总线db（Data Bus）：双向的,在CPU与RAM之间来回传送需要处理或是需要储存的数据。宽度决定了CPU和计算机其他设备之间每次交换数据的位数
 地址总线ab（Address Bus）：单向的,用来指定在RAM（Random Access Memory）之中储存的数据的地址。宽度决定了CPU的最大寻址能力
 控制总线cb（Control Bus）：(单根总线单向的信号)整体是双向线，将微处理器控制单元（Control Unit）的信号，传送到周边设备。传送控制信号、时序信号和状态信息等
 扩展总线eb（Expansion Bus）：外部设备和计算机主机进行数据通信的总线，例如ISA总线，PCI总线。
 局部总线lb（Local Bus）：取代更高速数据传输的扩展总线。
 64位处理器的定义是拥有数据宽度为64位的寄存器，并且可以一次传输、运算64位的数据
 
 1. Cache：缓存区，是高速缓存，是位于CPU和主内存之间的容量较小但速度很快的存储器，因为CPU的速度远远高于主内存的速度，CPU从内存中读取数据需等待很长的时间，而 Cache保存着CPU刚用过的数据或循环使用的部分数据，这时从Cache中读取数据会更快，减少了CPU等待的时间，提高了系统的性能。
 Cache并不是缓存文件的，而是缓存块的(块是I/O读写最小的单元)；Cache一般会用在I/O请求上，如果多个进程要访问某个文件，可以把此文件读入Cache中，这样下一个进程获取CPU控制权并访问此文件直接从Cache读取，提高系统性能。
 2. Buffer：缓冲区，用于存储速度不同步的设备或优先级不同的设备之间传输数据；通过buffer可以减少进程间通信需要等待的时间，当存储速度快的设备与存储速度慢的设备进行通信时，存储慢的数据先把数据存放到buffer，达到一定程度存储快的设备再读取buffer的数据，在此期间存储快的设备CPU可以干其他的事情。
 Buffer：一般是用在写入磁盘的，例如：某个进程要求多个字段被读入，当所有要求的字段被读入之前已经读入的字段会先放到buffer中。
 内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少
 
 静态分配内存就是编译器在编译程序的时候根据源程序来分配内存. 动态分配内存就是在程序编译之后, 运行时调用运行时刻库函数来分配内存的. 静态分配由于是在程序运行之前,所以速度快, 效率高, 但是局限性大. 动态分配在程序运行时执行, 所以速度慢, 但灵活性高.
 普通进程涉及到5种不同的数据段：
 代码段：存放可执行文件的操作指令，也就是说是它是可执行程序在内存中的镜像。代码段需要防止在运行时被非法修改，所以只准许读取操作，而不允许写入（修改）操作——它是不可写的。
 数据段：数据段用来存放可执行文件中已初始化全局变量，换句话说就是存放程序静态分配[1]的变量和全局变量。
 BSS段：BSS段包含了程序中未初始化的全局变量，在内存中 bss段全部置零。
 堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）
 栈：栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。
 
 
 Linux操作系统采用虚拟内存管理技术，使得每个进程都有各自互不干涉的进程地址空间。该空间是块大小为4G的线性虚拟空间，用户所看到和接触到的都是该虚拟地址
 （4G是对32位系统2**32而言的）用户空间与内核空间。用户空间从0到3G（0xC0000000），内核空间占据3G到4G。用户进程通常情况下只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址。只有用户进程进行系统调用（代表用户进程在内核态执行）等时刻可以访问到内核空间
 用户空间对应进程，所以每当进程切换，用户空间就会跟着变化；而内核空间是由内核负责映射，它并不会跟着进程改变，是固定的。内核空间地址有自己对应的页表（init_mm.pgd），用户进程各自有不同的页表
 物理内存管理（页管理）：CPU和操作系统提供了一种虚拟地址到实际物理地址的映射机制，在页映射模式下，CPU发出的是虚拟地址，即进程看到的虚拟的地址，经过MMU（Memory Management Unit）部件转换之后就成了物理地址。
 Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数个4k（在i386体系结构中）大小的页，从而分配和回收内存的基本单位便是内存页了
 1.“伙伴”关系来管理空闲页面。分配4(2^2)页（16k）的内存空间，算法会先从free_area中查看nr_free是否为空，如果有空闲块，则从中分配，如果没有空闲块，就从它的上一级free_area（每块32K）中分配出16K，并将多余的内存（16K）加入到free_area中去。如果free_area也没有空闲，则从更上一级申请空间，依次递推，直到free_area[max_order]，如果顶级都没有空间，那么就报告分配失败。
 2.内核内存使用Slab分配器，slab仍然是建立在页面基础之上，原理，其核心思想就是“存储池”的运用。内存片段（小块内存）被看作对象，当被使用完后，并不直接释放而是被缓存到“存储池”里，留做下次使用，
 Kmalloc用来存放内核专用的结构体，内核非连续内存分配（Vmalloc）
 防止“分片”，不过分片又分为外部分片和内部分片之说，所谓内部分片是说系统为了满足一小段内存区（连续）的需要，不得不分配了一大区域连续内存给它，从而造成了空间浪费；外部分片是指系统虽有足够的内存，但却是分散的碎片，无法满足对大块“连续内存”的需求。无论何种分片都是系统有效利用内存的障碍。slab分配器使得一个页面内包含的众多小块内存可独立被分配使用，避免了内部分片，节约了空闲内存。伙伴关系把内存块按大小分组管理，
 避免外部分片的最终思路还是落到了如何利用不连续的内存块组合成“看起来很大的内存块”
 
 /dev/shm分区的大小是系统物理内存的50%,默认的Linux发行版中的内核配置都会开启tmpfs，映射到了/dev/下的shm目录。可以通过df 命令查看结果.
 /dev/shm/是linux下一个非常有用的目录，因为这个目录不在硬盘上，而是在内存里
 tmpfs有以下优势： 
 1。动态文件系统的大小，/dev/shm/需要注意的一个是容量问题，在linux下，它默认最大为内存的一半大小，使用df -h命令可以看到。但它并不会真正的占用这块内存，如果/dev/shm/下没有任何文件，它占用的内存实际上就是0字节；如果它最大为1G，里头放有 100M文件，那剩余的900M仍然可为其它应用程序所使用，但它所占用的100M内存，是绝不会被系统回收重新划分的 
 2。tmpfs 的另一个主要的好处是它闪电般的速度。因为典型的 tmpfs 文件系统会完全驻留在 RAM 中，读写几乎可以是瞬间的。 
 3。tmpfs 数据在重新启动之后不会保留，因为虚拟内存本质上就是易失的。所以有必要做一些脚本做诸如加载，绑定的操作。
 临时重挂载：mount -o size=1500M -o nr_inodes=1000000 -o noatime,nodiratime -o remount /dev/shm
 永久：tmpfs /dev/shm tmpfs defaults,size=1.5G 0 0
       mount -o remount /dev/shm
 mkdir /dev/shm/tmp  && chmod 1777 /dev/shm/tmp  && mount –bind /dev/shm/tmp /tmp
 
 tmpfs是Linux/Unix系统上的一种基于内存的文件系统。tmpfs可以使用您的内存或swap分区来存储文件。由此可见，temfs主要存储暂存的文件。
 linux内核中的VM子系统负责在后台管理虚拟内存资源Virtual Memory，即RAM和swap资源，透明地将RAM页移动到交换分区或从交换分区到RAM页，tmpfs文件系统需要VM子系统的页面来存储文件。tmpfs自己并不知道这些页面是在交换分区还是在RAM中；做这种决定是VM子系统的工作。tmpfs文件系统所知道的就是它正在使用某种形式的虚拟内存。
 
 ramdisk（虚拟磁盘）:需要格式化
 mmap（一种内存映射文件的方法）将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零
 
 
